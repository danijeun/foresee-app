# Foresee App

**Automated Machine Learning Analysis & Reporting Platform**

Foresee is an intelligent web application that automates the entire machine learning workflow: from data upload to model training to generating professional PDF reports. Built with a multi-agent architecture powered by AI, it makes advanced ML analysis accessible to everyone.

---

## ğŸ¯ What Does It Do?

Upload a CSV file â†’ Get professional ML insights in minutes

1. **Upload** your dataset (CSV format)
2. **AI suggests** the best target variables to predict
3. **Select** your prediction target
4. **Automatic training** of 3 ML models (Logistic Regression, Decision Tree, XGBoost)
5. **Download** a comprehensive PDF report with insights and recommendations

---

## âœ¨ Key Features

### ğŸ¤– **AI-Powered Target Selection**
- Uses Google Gemini to analyze your dataset
- Recommends the top 5 most valuable prediction targets
- Provides importance scores and business rationale
- Distinguishes between target variables and features

### ğŸ“Š **Automatic Exploratory Data Analysis (EDA)**
- Comprehensive statistical analysis of all columns
- Detects data types, missing values, duplicates
- Calculates numeric metrics (mean, std, quartiles, skewness, kurtosis)
- Analyzes categorical distributions and cardinality
- Identifies datetime patterns and text characteristics
- Stores all results in Snowflake for querying

### ğŸš€ **Parallel Model Training**
Trains 3 machine learning models simultaneously:
- **Logistic Regression**: Fast, interpretable baseline
- **Decision Tree**: Captures non-linear patterns
- **XGBoost**: State-of-the-art gradient boosting

Each model provides:
- Performance metrics (accuracy, precision, recall, F1, ROC-AUC)
- Feature importance rankings
- Confusion matrices
- Model-specific insights

### ğŸ“„ **Professional PDF Reports**
- AI-generated natural language insights
- Data quality assessment
- Model performance comparisons
- Feature importance analysis
- Visualizations and charts
- Actionable recommendations

### â„ï¸ **Snowflake Integration**
- Scalable data warehouse for enterprise datasets
- Isolated workflow schemas (one per upload)
- SQL-based data processing
- Secure data storage

### âš¡ **Modern Web Interface**
- React frontend with Tailwind CSS
- Drag-and-drop file upload
- Real-time progress tracking
- Interactive model selection
- Responsive design

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend                            â”‚
â”‚                      (React + Vite)                         â”‚
â”‚                                                              â”‚
â”‚  â€¢ File upload interface                                    â”‚
â”‚  â€¢ Target variable selection                                â”‚
â”‚  â€¢ Progress tracking                                        â”‚
â”‚  â€¢ Report viewing/download                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ REST API
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Backend (Flask)                          â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚           Multi-Agent System                        â”‚    â”‚
â”‚  â”‚                                                      â”‚    â”‚
â”‚  â”‚  â€¢ EDA Agent          â†’ Analyze data               â”‚    â”‚
â”‚  â”‚  â€¢ Target Agent       â†’ Suggest targets (Gemini)   â”‚    â”‚
â”‚  â”‚  â€¢ ML Agents (3x)     â†’ Train models               â”‚    â”‚
â”‚  â”‚  â€¢ NL Insights Agent  â†’ Generate report (Gemini)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Snowflake                                â”‚
â”‚                                                              â”‚
â”‚  â€¢ WORKFLOW_<UUID> schemas (isolated per upload)           â”‚
â”‚  â€¢ Raw data tables                                          â”‚
â”‚  â€¢ EDA results (workflow_eda_summary, column_stats)        â”‚
â”‚  â€¢ ML results (logistic/tree/xgboost_summary)              â”‚
â”‚  â€¢ Metadata storage                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Application Workflow

### 1. Data Upload & EDA (Parallel)
```
User uploads CSV
    â”‚
    â”œâ”€â†’ Store in Snowflake â†’ EDA Agent analyzes data
    â”‚
    â””â”€â†’ Target Variable Agent suggests targets (Gemini AI)
```

### 2. Target Selection
```
User sees AI recommendations (ranked 1-5)
    â”‚
    â””â”€â†’ Selects target variable â†’ Saves to workflow metadata
```

### 3. Model Training (Sequential)
```
Train Logistic Regression
    â”‚
    â”œâ”€â†’ Feature engineering
    â”œâ”€â†’ Model training
    â”œâ”€â†’ Performance evaluation
    â””â”€â†’ Save results to Snowflake
    
Train Decision Tree
    â”‚
    â””â”€â†’ [same steps]
    
Train XGBoost
    â”‚
    â””â”€â†’ [same steps]
```

### 4. Report Generation
```
Natural Language Agent (Gemini)
    â”‚
    â”œâ”€â†’ Collect EDA insights
    â”œâ”€â†’ Collect ML results
    â”œâ”€â†’ Generate narrative insights
    â”œâ”€â†’ Create visualizations
    â””â”€â†’ Generate PDF report
```

---

## ğŸ› ï¸ Technology Stack

### Frontend
- **React 19** with **Vite**
- **Tailwind CSS** for styling
- **React Router** for navigation
- **AOS** for animations

### Backend
- **Python 3.11+**
- **Flask 3.0** for REST API
- **Flask-CORS** for cross-origin requests

### AI & ML
- **Google Gemini 2.0/2.5** (via `google-generativeai`)
  - Target variable recommendations
  - Natural language insights generation
- **scikit-learn 1.5.0** (Logistic Regression, Decision Tree)
- **XGBoost 2.1.0** (Gradient Boosting)
- **SHAP 0.44.0** (Model explainability)
- **pandas 2.2.0** & **NumPy 1.26.0**

### Data Platform
- **Snowflake** (Data Warehouse)
  - `snowflake-connector-python 3.12.0`
  - `snowflake-snowpark-python 1.39.1`

### Report Generation
- **ReportLab 4.0.7** (PDF generation)
- **Matplotlib 3.8.0** (Visualizations)

---

## ğŸ“‹ Project Structure

```
foresee-app/
â”œâ”€â”€ frontend/                    # React application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.jsx        # Landing page
â”‚   â”‚   â”‚   â”œâ”€â”€ Foresee.jsx     # Main app interface
â”‚   â”‚   â”‚   â”œâ”€â”€ AboutUs.jsx     # About page
â”‚   â”‚   â”‚   â””â”€â”€ Help.jsx        # Help page
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ TopBanner.jsx   # Navigation header
â”‚   â”‚   â”‚   â””â”€â”€ Footer.jsx      # Footer
â”‚   â”‚   â”œâ”€â”€ App.jsx             # Main app component
â”‚   â”‚   â””â”€â”€ main.jsx            # Entry point
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ backend/                     # Flask API + Agents
â”‚   â”œâ”€â”€ app.py                  # Main Flask application
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                 # ML & AI Agents
â”‚   â”‚   â”œâ”€â”€ eda_agent/          # EDA Agent (Snowflake-based)
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py        # Main EDA logic
â”‚   â”‚   â”‚   â”œâ”€â”€ database/       # Snowflake connection & storage
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics/        # Metric calculators (numeric, categorical, etc.)
â”‚   â”‚   â”‚   â””â”€â”€ utils/          # Helpers & validators
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ target_variable_agent.py    # AI target recommendations (Gemini)
â”‚   â”‚   â”œâ”€â”€ logistic_regression_agent.py # Logistic Regression trainer
â”‚   â”‚   â”œâ”€â”€ decision_tree_agent.py       # Decision Tree trainer
â”‚   â”‚   â”œâ”€â”€ xgboost_agent.py             # XGBoost trainer
â”‚   â”‚   â””â”€â”€ natural_language_agent.py    # PDF report generator (Gemini)
â”‚   â”‚
â”‚   â”œâ”€â”€ services/               # Business logic services
â”‚   â”‚   â”œâ”€â”€ workflow_manager.py # Workflow & schema management
â”‚   â”‚   â”œâ”€â”€ snowflake_ingestion.py # CSV upload to Snowflake
â”‚   â”‚   â”œâ”€â”€ eda_service.py      # EDA orchestration
â”‚   â”‚   â””â”€â”€ config.py           # Configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ insights/               # Generated JSON insights
â”‚   â””â”€â”€ pdf/                    # Generated PDF reports
â”‚
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.11+**
- **Node.js 18+**
- **Snowflake account** (with credentials)
- **Google Gemini API key** ([Get one here](https://aistudio.google.com/app/apikey))

### Installation

#### 1. Clone the repository
```bash
git clone https://github.com/yourusername/foresee-app.git
cd foresee-app
```

#### 2. Set up backend

```bash
# Create virtual environment
python -m venv myenv

# Activate virtual environment
# Windows:
myenv\Scripts\activate
# macOS/Linux:
source myenv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### 3. Configure environment variables

Create a `.env` file in the project root:

```env
# Snowflake Configuration
SNOWFLAKE_ACCOUNT=your_account_identifier
SNOWFLAKE_USER=your_username
SNOWFLAKE_PASSWORD=your_password
SNOWFLAKE_WAREHOUSE=your_warehouse
SNOWFLAKE_DATABASE=your_database
SNOWFLAKE_SCHEMA=PUBLIC
SNOWFLAKE_ROLE=your_role

# Google Gemini API
GEMINI_API_KEY=your_gemini_api_key
```

#### 4. Set up frontend

```bash
cd frontend
npm install
```

---

## ğŸ¬ Running the Application

### Option 1: Quick Start (One Terminal) â­

**Windows:**
```bash
start.bat
```

**macOS/Linux:**
```bash
chmod +x start.sh  # First time only
./start.sh
```

This will automatically:
1. Activate the Python virtual environment
2. Start the backend server
3. Start the frontend dev server

### Option 2: Using npm (One Terminal)

First, install `concurrently`:
```bash
cd frontend
npm install
```

Then run both servers:
```bash
npm run dev:all
```

### Option 3: Manual (Two Terminals)

**Terminal 1 - Backend:**
```bash
# Activate virtual environment
myenv\Scripts\activate  # Windows
# or
source myenv/bin/activate  # macOS/Linux

# Start Flask server
cd backend
python app.py
```

**Terminal 2 - Frontend:**
```bash
cd frontend
npm run dev
```

### Access the Application

Open your browser and navigate to:
- **Frontend:** `http://localhost:5173`
- **Backend API:** `http://localhost:5000`
- **API Docs:** `http://localhost:5000/api/health` (health check)

---

## ğŸ“– Usage Guide

### 1. Upload Your Dataset

- Click **"Foresee"** in the navigation menu
- Drag & drop your CSV file or click **"Choose File"**
- Click **"Upload & Analyze"**

The system will:
- Upload your data to Snowflake
- Run automatic EDA analysis
- Generate target variable recommendations (using AI)

### 2. Select Target Variable

After upload, you'll see 3 recommended targets in a podium layout:
- ğŸ¥‡ **Gold** (Most important)
- ğŸ¥ˆ **Silver** (Second best)
- ğŸ¥‰ **Bronze** (Third option)

Click **"Other Options"** to see all 5 recommendations with detailed explanations.

Each recommendation includes:
- **Importance Score** (1-100)
- **Problem Type** (regression/classification)
- **Why Important** (business value)
- **Predictability** (HIGH/MEDIUM/LOW)
- **Suggested Features** (best predictors)

### 3. Model Training

After selecting a target, the system automatically:
1. Trains 3 ML models (10-15 seconds)
2. Evaluates performance metrics
3. Generates natural language insights
4. Creates a PDF report

### 4. View/Download Report

When complete:
- Click **"View Report"** to see it in browser
- Click **"Download Report"** to save PDF

---

## ğŸ“Š What's in the Report?

### Executive Summary
- Dataset overview
- Target variable selected
- Best performing model

### Data Analysis
- Data quality metrics
- Missing value analysis
- Duplicate detection
- Column type breakdown

### Model Performance
- Comparison table (all 3 models)
- Performance metrics:
  - Accuracy
  - Precision
  - Recall
  - F1 Score
  - ROC-AUC
- Confusion matrices

### Feature Importance
- Top 10 most important features
- SHAP value analysis (planned)
- Feature distributions

### Recommendations
- Model selection advice
- Data quality improvements
- Next steps for deployment

---

## ğŸ¯ API Endpoints

### Core Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/health` | Health check |
| `POST` | `/api/upload` | Upload CSV & run EDA + Target Agent |
| `GET` | `/api/workflows` | List all workflows |
| `DELETE` | `/api/workflow/<id>` | Delete a workflow |
| `POST` | `/api/query` | Execute SQL query |

### Target Variable Selection

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/target-suggestions/<workflow_id>/<table_name>` | Get AI recommendations |
| `POST` | `/api/workflow/<id>/select-target` | Save target & auto-train models |

### ML Model Training (Manual)

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/workflow/<id>/train-logistic-regression` | Train logistic regression |
| `POST` | `/api/workflow/<id>/train-decision-tree` | Train decision tree |
| `POST` | `/api/workflow/<id>/train-xgboost` | Train XGBoost |

### Model Results

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/workflow/<id>/logistic-regression-results` | Get LR results |
| `GET` | `/api/workflow/<id>/decision-tree-results` | Get DT results |
| `GET` | `/api/workflow/<id>/xgboost-results` | Get XGB results |

### Report Generation

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/workflow/<id>/generate-insights` | Generate insights & PDF |
| `GET` | `/api/workflow/<id>/report/view` | View PDF in browser |
| `GET` | `/api/workflow/<id>/report/download` | Download PDF |

---

## ğŸ—„ï¸ Database Schema (Snowflake)

Each workflow creates an isolated schema: `WORKFLOW_<UUID>`

### Tables Created Per Workflow

#### `WORKFLOW_METADATA`
Stores workflow-level metadata including selected target variable.

#### `WORKFLOW_EDA_SUMMARY`
```sql
- analysis_id (UUID)
- table_name (VARCHAR)
- total_rows (INT)
- total_columns (INT)
- duplicate_rows (INT)
- target_column (VARCHAR)
- analysis_type (VARCHAR)
- created_at (TIMESTAMP)
```

#### `COLUMN_STATS`
Detailed statistics for each column:
- Basic metrics (null_count, unique_count, completeness)
- Numeric metrics (mean, std, min, max, quartiles, skewness, kurtosis)
- Categorical metrics (mode, top values, cardinality)
- Text metrics (avg_length, max_length)
- Datetime metrics (date_range, frequency)

#### `LOGISTIC_REGRESSION_SUMMARY`
```sql
- analysis_id (UUID)
- target_variable (VARCHAR)
- test_accuracy (FLOAT)
- test_precision (FLOAT)
- test_recall (FLOAT)
- test_f1_score (FLOAT)
- test_roc_auc (FLOAT)
- confusion_matrix (ARRAY)
- top_features (ARRAY)
- recommendations (VARCHAR)
```

#### `DECISION_TREE_SUMMARY`
Same structure as Logistic Regression + tree-specific metrics:
- tree_depth (INT)
- n_leaves (INT)
- max_depth (INT)

#### `XGBOOST_SUMMARY`
Same structure + XGBoost-specific metrics:
- n_estimators (INT)
- max_depth (INT)
- learning_rate (FLOAT)

---

## âš™ï¸ Configuration

### Backend Configuration

Located in `backend/services/config.py`:

```python
# Snowflake connection loaded from .env
SNOWFLAKE_ACCOUNT
SNOWFLAKE_USER
SNOWFLAKE_PASSWORD
SNOWFLAKE_WAREHOUSE
SNOWFLAKE_DATABASE
SNOWFLAKE_SCHEMA

# AI Configuration
GEMINI_API_KEY

# Flask Settings
MAX_FILE_SIZE = 500 MB
ALLOWED_EXTENSIONS = ['csv']
```

### Frontend Configuration

Located in `frontend/src/pages/Foresee.jsx`:

```javascript
const API_BASE_URL = "http://localhost:5000/api";
```

Change this to your backend URL in production.

---

## ğŸ”’ Security & Privacy

### Data Isolation
- Each upload creates an isolated Snowflake schema
- No data mixing between workflows
- Automatic cleanup on workflow deletion

### API Security
- CORS enabled for frontend-backend communication
- File size limits (500MB max)
- File type validation (CSV only)

### Data Privacy
- Data stored in your Snowflake account
- AI models don't retain your data
- Gemini API calls are stateless

---

## ğŸ› Troubleshooting

### Backend won't start
```bash
# Check Python version
python --version  # Should be 3.11+

# Verify .env file exists with all required variables
cat .env

# Check Snowflake connection
# Try connecting manually with snowsql or Snowflake web UI
```

### Frontend can't connect to backend
```bash
# Verify backend is running on port 5000
curl http://localhost:5000/api/health

# Check CORS is enabled in backend/app.py
# Verify API_BASE_URL in frontend matches backend
```

### Upload fails
- Check file is valid CSV
- Verify Snowflake credentials
- Check Snowflake warehouse is running
- Ensure sufficient Snowflake credits

### Gemini API errors
- Verify `GEMINI_API_KEY` is set correctly
- Check API quota limits
- Test API key at: https://aistudio.google.com/

### Model training fails
- Check target variable has valid data
- Ensure target has sufficient unique values
- Verify no excessive missing values

---

## ğŸ“ˆ Roadmap

### Planned Features
- [ ] Support for more ML models (Random Forest, Neural Networks)
- [ ] Advanced hyperparameter tuning
- [ ] Time series forecasting support
- [ ] Interactive charts in reports
- [ ] Model deployment API
- [ ] Scheduled re-training
- [ ] User authentication
- [ ] Multi-user workspaces
- [ ] Excel file support
- [ ] Real-time model monitoring

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines
- Follow PEP 8 for Python code
- Use ESLint rules for JavaScript/React
- Write docstrings for all functions
- Add tests for new features
- Update documentation

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

### Technologies
- **Snowflake** - Enterprise data platform
- **Google Gemini** - AI-powered insights
- **React** - Modern web framework
- **Flask** - Lightweight Python API
- **scikit-learn** & **XGBoost** - ML frameworks
- **ReportLab** - PDF generation

### Team
Built with â¤ï¸ by the Foresee Team

---

## ğŸ“ Support

For issues, questions, or suggestions:
- ğŸ“§ Email: support@foresee-app.com
- ğŸ› Issues: [GitHub Issues](https://github.com/yourusername/foresee-app/issues)
- ğŸ“š Documentation: [Wiki](https://github.com/yourusername/foresee-app/wiki)

---

**Happy Analyzing! ğŸš€**