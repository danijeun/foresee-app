# Foresee - AI-Powered AutoML Platform

**Automated Machine Learning Analysis & Reporting with Google Gemini AI**

Foresee is an intelligent web application that transforms raw data into actionable ML insights. Upload a CSV file and get professional ML analysis reports with AI-powered target variable recommendations, automated model training, and comprehensive PDF reportsâ€”all in minutes.

---

## ğŸ¯ What Does Foresee Do?

**From CSV to ML Insights in 5 Simple Steps:**

1. **Upload** your dataset (CSV format)
2. **AI Analysis** - Google Gemini automatically suggests the best target variables to predict
3. **Select** your prediction target from ranked recommendations
4. **Auto-Train** - System trains 3 ML models in parallel (Logistic Regression, Decision Tree, XGBoost)
5. **Download** a comprehensive PDF report with insights, metrics, and recommendations

---

## âœ¨ Key Features

### ğŸ¤– **AI-Powered Target Selection (Google Gemini 2.5)**
- Uses **Google Gemini 2.5 Flash** (`gemini-2.5-flash-preview-05-20`) to intelligently analyze your dataset
- Recommends the **top 5 most valuable prediction targets** with importance scores (1-100)
- Distinguishes between target variables (outcomes) and features (predictors)
- Provides detailed business rationale, predictability assessment, and suggested features
- Runs in **parallel** with EDA for faster results

### ğŸ“Š **Automatic Exploratory Data Analysis (EDA)**
- **Snowflake-based** comprehensive statistical analysis
- Analyzes all column types: numeric, categorical, datetime, text
- Detects data types, missing values, duplicates, and cardinality
- Calculates metrics: mean, std, quartiles, skewness, kurtosis, top values
- Stores all results in **Snowflake** for querying and persistence
- **Parallel execution** with Target Analysis for optimal performance

### ğŸš€ **Multi-Model Machine Learning**
Trains **3 models sequentially** after target selection:

| Model | Description | Key Metrics |
|-------|-------------|-------------|
| **Logistic Regression** | Fast, interpretable baseline | Accuracy, Precision, Recall, F1, ROC-AUC |
| **Decision Tree** | Non-linear pattern detection | Tree depth, leaves, feature importance |
| **XGBoost** | State-of-the-art gradient boosting | N-estimators, max depth, learning rate |

Each model provides:
- Performance metrics (train & test)
- Confusion matrices
- Feature importance rankings
- Model-specific recommendations
- Data quality assessments

### ğŸ“„ **Professional PDF Reports (AI-Generated)**
- **Natural language insights** generated by Google Gemini
- Executive summary with best-performing model
- Data quality and EDA insights
- Model performance comparisons
- Feature importance analysis
- Actionable recommendations
- Professional charts and visualizations

### â„ï¸ **Snowflake Data Platform**
- **Isolated workflow schemas** - Each upload creates `WORKFLOW_<UUID>` schema
- Scalable data warehouse for enterprise datasets
- SQL-based data processing and storage
- Persistent storage for all EDA and ML results
- Clean separation between workflows

### âš¡ **Modern Web Interface (React + Tailwind)**
- Drag-and-drop file upload
- Real-time progress tracking with rotating status messages
- Interactive podium display for top 3 target recommendations
- Responsive design for all devices
- Smooth animations with AOS (Animate On Scroll)
- In-browser PDF viewing and download

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (React 19 + Vite)                   â”‚
â”‚                                                                  â”‚
â”‚  â€¢ Drag & drop file upload       â€¢ Podium target display       â”‚
â”‚  â€¢ Real-time progress tracking   â€¢ PDF viewer                  â”‚
â”‚  â€¢ Target variable selection     â€¢ Responsive UI               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ REST API (CORS enabled)
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  BACKEND (Flask 3.0 API)                        â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚               MULTI-AGENT SYSTEM                          â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  1ï¸âƒ£ EDA Agent (Parallel)                                  â”‚  â”‚
â”‚  â”‚     â†’ Analyze dataset                                     â”‚  â”‚
â”‚  â”‚     â†’ Store stats in Snowflake                           â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  2ï¸âƒ£ Target Variable Agent (Parallel) - Gemini 2.5        â”‚  â”‚
â”‚  â”‚     â†’ Sample data                                         â”‚  â”‚
â”‚  â”‚     â†’ LLM analysis                                        â”‚  â”‚
â”‚  â”‚     â†’ Rank top 5 targets (importance scores)            â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  3ï¸âƒ£ ML Training Agents (Sequential after target select)  â”‚  â”‚
â”‚  â”‚     â†’ Logistic Regression Agent                          â”‚  â”‚
â”‚  â”‚     â†’ Decision Tree Agent                                â”‚  â”‚
â”‚  â”‚     â†’ XGBoost Agent                                      â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  4ï¸âƒ£ Natural Language Agent - Gemini 2.5                  â”‚  â”‚
â”‚  â”‚     â†’ Collect EDA & ML results                           â”‚  â”‚
â”‚  â”‚     â†’ Generate insights (LLM)                            â”‚  â”‚
â”‚  â”‚     â†’ Create PDF report (ReportLab)                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚  Services:                                                      â”‚
â”‚  â€¢ Workflow Manager     â€¢ Snowflake Ingestion                  â”‚
â”‚  â€¢ EDA Service          â€¢ Config Management                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ Snowflake Connector
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SNOWFLAKE DATA PLATFORM                      â”‚
â”‚                                                                  â”‚
â”‚  Isolated Schemas: WORKFLOW_<UUID>                             â”‚
â”‚                                                                  â”‚
â”‚  Tables per Workflow:                                          â”‚
â”‚  â€¢ WORKFLOW_METADATA          â†’ Workflow info                  â”‚
â”‚  â€¢ WORKFLOW_EDA_SUMMARY       â†’ EDA results                    â”‚
â”‚  â€¢ COLUMN_STATS               â†’ Column metrics                 â”‚
â”‚  â€¢ LOGISTIC_REGRESSION_SUMMARY â†’ LR model results             â”‚
â”‚  â€¢ DECISION_TREE_SUMMARY       â†’ DT model results             â”‚
â”‚  â€¢ XGBOOST_SUMMARY             â†’ XGB model results            â”‚
â”‚  â€¢ RAW_DATA_TABLE              â†’ Original CSV data            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Application Workflow

### **Phase 1: Upload & Parallel Analysis** (45-60s)

```
User uploads CSV
    â”‚
    â”œâ”€â†’ Store in Snowflake (temp file â†’ Snowflake table)
    â”‚
    â”œâ”€â†’ ğŸ§µ Thread 1: EDA Agent
    â”‚       â””â”€â†’ Analyze all columns
    â”‚           â””â”€â†’ Save to WORKFLOW_EDA_SUMMARY
    â”‚
    â””â”€â†’ ğŸ§µ Thread 2: Target Variable Agent (Gemini 2.5)
            â””â”€â†’ Sample 100 rows
                â””â”€â†’ LLM analysis
                    â””â”€â†’ Return top 5 targets (ranked)
```
**Time Saved:** ~40% faster than sequential execution

---

### **Phase 2: Target Selection** (User interaction)

```
Frontend displays 3 recommendations in podium:
    ğŸ¥‡ Gold   (Rank 1 - Highest importance)
    ğŸ¥ˆ Silver (Rank 2)
    ğŸ¥‰ Bronze (Rank 3)
    
+ "Other Options" button â†’ Shows all 5 recommendations

Each recommendation includes:
    â€¢ Importance Score (1-100)
    â€¢ Problem Type (regression/classification)
    â€¢ Why Important (business value)
    â€¢ Predictability (HIGH/MEDIUM/LOW)
    â€¢ Suggested Features (top predictors)

User selects target â†’ Saved to workflow_metadata
```

---

### **Phase 3: Sequential ML Training** (10-15s)

```
Automatic training after target selection:

1. Logistic Regression Agent
    â”œâ”€â†’ Feature engineering
    â”œâ”€â†’ Train/test split (80/20)
    â”œâ”€â†’ Model training (max_iter=1000)
    â”œâ”€â†’ Performance evaluation
    â””â”€â†’ Save to LOGISTIC_REGRESSION_SUMMARY

2. Decision Tree Agent
    â”œâ”€â†’ Feature engineering
    â”œâ”€â†’ Train/test split (80/20)
    â”œâ”€â†’ Model training (max_depth=10)
    â”œâ”€â†’ Performance evaluation
    â””â”€â†’ Save to DECISION_TREE_SUMMARY

3. XGBoost Agent
    â”œâ”€â†’ Feature engineering
    â”œâ”€â†’ Train/test split (80/20)
    â”œâ”€â†’ Model training (n_estimators=100, max_depth=6)
    â”œâ”€â†’ Performance evaluation
    â””â”€â†’ Save to XGBOOST_SUMMARY
```

---

### **Phase 4: Report Generation** (5-10s)

```
Natural Language Agent (Gemini 2.5)
    â”‚
    â”œâ”€â†’ Collect EDA insights from Snowflake
    â”œâ”€â†’ Collect ML results (all 3 models)
    â”œâ”€â†’ Generate narrative with Gemini LLM
    â”œâ”€â†’ Create visualizations (Matplotlib)
    â”œâ”€â†’ Generate PDF (ReportLab)
    â””â”€â†’ Save to backend/pdf/
```

**Total Time:** ~60-85 seconds from upload to PDF

---

## ğŸ› ï¸ Technology Stack

### **Frontend**
| Library | Version | Purpose |
|---------|---------|---------|
| **React** | 19.1.1 | UI framework |
| **React Router** | 7.9.3 | Navigation |
| **Vite** | 7.1.7 | Build tool & dev server |
| **Tailwind CSS** | 4.1.14 | Styling framework |
| **AOS** | 2.3.4 | Scroll animations |
| **ESLint** | 9.36.0 | Code linting |

### **Backend**
| Library | Version | Purpose |
|---------|---------|---------|
| **Flask** | 3.0.0 | REST API framework |
| **Flask-CORS** | 4.0.0 | Cross-origin support |
| **python-dotenv** | 1.0.1 | Environment config |

### **AI & Machine Learning**
| Library | Version | Purpose |
|---------|---------|---------|
| **google-generativeai** | 0.8.3 | Google Gemini 2.5 API |
| **scikit-learn** | 1.5.0 | Logistic Regression, Decision Tree |
| **XGBoost** | 2.1.0 | Gradient boosting |
| **SHAP** | 0.44.0 | Model explainability |
| **pandas** | 2.2.0 | Data manipulation |
| **NumPy** | 1.26.0 | Numerical operations |

### **Data Platform**
| Library | Version | Purpose |
|---------|---------|---------|
| **snowflake-connector-python** | 3.12.0 | Snowflake connectivity |
| **snowflake-snowpark-python** | 1.39.1 | Snowpark DataFrame API |

### **Reporting & Visualization**
| Library | Version | Purpose |
|---------|---------|---------|
| **ReportLab** | 4.0.7 | PDF generation |
| **Matplotlib** | 3.8.0 | Charts & visualizations |

---

## ğŸ“‹ Project Structure

```
foresee-app/
â”œâ”€â”€ frontend/                           # React Application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.jsx               # Landing page
â”‚   â”‚   â”‚   â”œâ”€â”€ Foresee.jsx            # Main app (upload, analysis, results)
â”‚   â”‚   â”‚   â”œâ”€â”€ AboutUs.jsx            # Team information
â”‚   â”‚   â”‚   â””â”€â”€ Help.jsx               # User guide
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ TopBanner.jsx          # Navigation header
â”‚   â”‚   â”‚   â””â”€â”€ Footer.jsx             # Footer
â”‚   â”‚   â”œâ”€â”€ App.jsx                    # Main component & routing
â”‚   â”‚   â””â”€â”€ main.jsx                   # Entry point
â”‚   â”œâ”€â”€ package.json                   # Frontend dependencies
â”‚   â””â”€â”€ vite.config.js                 # Vite configuration
â”‚
â”œâ”€â”€ backend/                            # Flask API + ML Agents
â”‚   â”œâ”€â”€ app.py                         # Main Flask API (1949 lines)
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                        # AI/ML Agents
â”‚   â”‚   â”œâ”€â”€ eda_agent/                 # EDA Agent (Snowflake-based)
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py               # Main EDA orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py              # EDA configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ connection.py      # Snowflake connection
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ schema.py          # Schema management
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ storage.py         # Results storage
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics/               # Metric calculators
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ basic_metrics.py   # Basic stats
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ numeric_metrics.py # Numeric stats
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ categorical_metrics.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ datetime_metrics.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ text_metrics.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ target_metrics.py
â”‚   â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚   â”‚       â”œâ”€â”€ helpers.py
â”‚   â”‚   â”‚       â”œâ”€â”€ logger.py
â”‚   â”‚   â”‚       â””â”€â”€ validators.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ target_variable_agent.py   # Gemini-powered target suggestions
â”‚   â”‚   â”œâ”€â”€ logistic_regression_agent.py
â”‚   â”‚   â”œâ”€â”€ decision_tree_agent.py
â”‚   â”‚   â”œâ”€â”€ xgboost_agent.py
â”‚   â”‚   â””â”€â”€ natural_language_agent.py  # Gemini-powered PDF generation
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ workflow_manager.py        # Workflow & schema management
â”‚   â”‚   â”œâ”€â”€ snowflake_ingestion.py     # CSV â†’ Snowflake
â”‚   â”‚   â”œâ”€â”€ eda_service.py             # EDA orchestration
â”‚   â”‚   â””â”€â”€ config.py                  # Configuration loader
â”‚   â”‚
â”‚   â”œâ”€â”€ insights/                      # Generated JSON insights
â”‚   â””â”€â”€ pdf/                           # Generated PDF reports
â”‚
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .env                               # Environment variables (not tracked)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ start.bat                          # Windows startup script
â”œâ”€â”€ start.sh                           # Linux/Mac startup script
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### **Prerequisites**

- **Python 3.11+** ([Download](https://www.python.org/downloads/))
- **Node.js 18+** ([Download](https://nodejs.org/))
- **Snowflake Account** ([Sign up](https://signup.snowflake.com/))
- **Google Gemini API Key** ([Get free key](https://aistudio.google.com/app/apikey))

---

### **Installation**

#### **1. Clone the repository**
```bash
git clone https://github.com/yourusername/foresee-app.git
cd foresee-app
```

#### **2. Set up backend**

```bash
# Create virtual environment
python -m venv myenv

# Activate virtual environment
# Windows:
myenv\Scripts\activate
# macOS/Linux:
source myenv/bin/activate

# Install Python dependencies
pip install -r requirements.txt
```

#### **3. Configure environment variables**

Create a `.env` file in the **project root**:

```env
# Snowflake Configuration
SNOWFLAKE_ACCOUNT=your_account_identifier
SNOWFLAKE_USER=your_username
SNOWFLAKE_PASSWORD=your_password
SNOWFLAKE_DATABASE=your_database
SNOWFLAKE_SCHEMA=PUBLIC
INGESTION_WAREHOUSE=your_warehouse

# Google Gemini API
GEMINI_API_KEY=your_gemini_api_key_here
```

**Get your Gemini API key:**
1. Visit https://aistudio.google.com/app/apikey
2. Sign in with Google account
3. Click **"Create API Key"**
4. Copy and paste into `.env`

#### **4. Set up frontend**

```bash
cd frontend
npm install
cd ..
```

---

## ğŸ¬ Running the Application

### **Option 1: Quick Start (Recommended) â­**

**Windows:**
```bash
start.bat
```

**macOS/Linux:**
```bash
chmod +x start.sh  # First time only
./start.sh
```

This automatically:
1. Activates Python virtual environment
2. Starts Flask backend (port 5000)
3. Starts Vite frontend (port 5173)

---

### **Option 2: Using npm**

```bash
cd frontend
npm run dev:all
```

Uses `concurrently` to run both servers simultaneously.

---

### **Option 3: Manual (Two Terminals)**

**Terminal 1 - Backend:**
```bash
# Activate virtual environment
myenv\Scripts\activate  # Windows
# or
source myenv/bin/activate  # macOS/Linux

# Start Flask server
cd backend
python app.py
```

**Terminal 2 - Frontend:**
```bash
cd frontend
npm run dev
```

---

### **Access the Application**

- **Frontend:** http://localhost:5173
- **Backend API:** http://localhost:5000
- **Health Check:** http://localhost:5000/api/health

---

## ğŸ“– Usage Guide

### **1. Upload Dataset**

1. Navigate to **"Foresee"** in the top menu
2. Drag & drop your CSV file or click **"Choose File"**
3. Click **"Upload & Analyze"**

The system will:
- Upload data to Snowflake
- Run **parallel** EDA + Target Analysis (~45-60s)
- Display progress with rotating status messages

---

### **2. Select Target Variable**

After analysis, you'll see:

**Podium Display (Top 3):**
- ğŸ¥‡ **Gold** - Most important target (Rank 1)
- ğŸ¥ˆ **Silver** - Second best (Rank 2)
- ğŸ¥‰ **Bronze** - Third option (Rank 3)

Click **"Other Options"** to see all 5 recommendations.

**Each recommendation shows:**
- **Importance Score** (1-100) - Quantitative ranking
- **Problem Type** - regression/classification
- **Why Important** - Business value explanation
- **Predictability** - HIGH/MEDIUM/LOW feasibility
- **Suggested Features** - Best predictor columns

---

### **3. Model Training (Automatic)**

After selecting a target, the system **automatically**:
1. Trains **Logistic Regression** model
2. Trains **Decision Tree** model
3. Trains **XGBoost** model
4. Generates **Natural Language Insights** (Gemini)
5. Creates **PDF Report** (ReportLab)

**Total Time:** 10-15 seconds

---

### **4. View/Download Report**

When complete:
- Click **"View Report"** â†’ Opens PDF in browser
- Click **"Download Report"** â†’ Saves PDF to your computer

---

## ğŸ“Š What's in the PDF Report?

### **1. Executive Summary**
- Dataset overview (rows, columns)
- Selected target variable
- Best-performing model
- Key findings

### **2. Data Quality Analysis**
- Missing value analysis
- Duplicate detection
- Column type breakdown
- Data completeness metrics

### **3. Exploratory Data Analysis**
- Numeric column statistics (mean, std, quartiles, skewness, kurtosis)
- Categorical distributions (top values, cardinality)
- Datetime patterns
- Text metrics

### **4. Model Performance Comparison**

| Model | Accuracy | Precision | Recall | F1 Score | ROC-AUC |
|-------|----------|-----------|--------|----------|---------|
| Logistic Regression | 0.85 | 0.82 | 0.88 | 0.85 | 0.91 |
| Decision Tree | 0.83 | 0.80 | 0.87 | 0.83 | 0.89 |
| XGBoost | 0.88 | 0.86 | 0.90 | 0.88 | 0.94 |

### **5. Feature Importance**
- Top 10 most important features
- Feature importance scores
- Model-specific interpretations

### **6. Model-Specific Insights**
- Confusion matrices
- Decision tree depth/leaves
- XGBoost hyperparameters
- Performance summaries

### **7. Recommendations**
- Best model selection advice
- Data quality improvements
- Feature engineering suggestions
- Next steps for deployment

---

## ğŸ¯ API Reference

### **Core Endpoints**

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/health` | Health check |
| `POST` | `/api/upload` | Upload CSV & run parallel analysis |
| `GET` | `/api/workflows` | List all workflows |
| `DELETE` | `/api/workflow/<id>` | Delete workflow & schema |
| `POST` | `/api/query` | Execute SQL query on workflow |

---

### **Target Variable Selection**

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/target-suggestions/<workflow_id>/<table_name>` | Get AI recommendations (Gemini) |
| `POST` | `/api/workflow/<id>/select-target` | Save target & auto-train models |

**POST Body:**
```json
{
  "target_variable": "column_name",
  "table_name": "table_name",
  "problem_type": "classification",
  "importance_score": 95
}
```

---

### **Manual Model Training** (Optional)

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/workflow/<id>/train-logistic-regression` | Train LR model |
| `POST` | `/api/workflow/<id>/train-decision-tree` | Train DT model |
| `POST` | `/api/workflow/<id>/train-xgboost` | Train XGBoost model |

---

### **Model Results**

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/workflow/<id>/logistic-regression-results` | Get LR results |
| `GET` | `/api/workflow/<id>/decision-tree-results` | Get DT results |
| `GET` | `/api/workflow/<id>/xgboost-results` | Get XGB results |

---

### **Report Generation**

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/workflow/<id>/generate-insights` | Generate insights & PDF (Gemini) |
| `GET` | `/api/workflow/<id>/report/view` | View PDF in browser |
| `GET` | `/api/workflow/<id>/report/download` | Download PDF |

---

## ğŸ—„ï¸ Snowflake Database Schema

Each workflow creates an **isolated schema**: `WORKFLOW_<UUID>`

### **Tables Created Per Workflow**

#### **1. WORKFLOW_METADATA**
```sql
CREATE TABLE WORKFLOW_METADATA (
    key VARCHAR,
    value VARIANT,
    updated_at TIMESTAMP
);
```
Stores workflow-level metadata (selected target, configuration).

---

#### **2. WORKFLOW_EDA_SUMMARY**
```sql
CREATE TABLE WORKFLOW_EDA_SUMMARY (
    analysis_id VARCHAR PRIMARY KEY,
    table_name VARCHAR,
    total_rows INTEGER,
    total_columns INTEGER,
    duplicate_rows INTEGER,
    target_column VARCHAR,
    analysis_type VARCHAR,
    created_at TIMESTAMP
);
```

---

#### **3. COLUMN_STATS**
```sql
CREATE TABLE COLUMN_STATS (
    column_name VARCHAR,
    data_type VARCHAR,
    null_count INTEGER,
    unique_count INTEGER,
    completeness FLOAT,
    -- Numeric metrics
    mean FLOAT,
    std FLOAT,
    min FLOAT,
    max FLOAT,
    q1 FLOAT,
    q2 FLOAT,
    q3 FLOAT,
    skewness FLOAT,
    kurtosis FLOAT,
    -- Categorical metrics
    mode VARCHAR,
    top_values VARIANT,
    cardinality INTEGER,
    -- Text metrics
    avg_length FLOAT,
    max_length INTEGER,
    -- Datetime metrics
    date_range VARIANT
);
```

---

#### **4. LOGISTIC_REGRESSION_SUMMARY**
```sql
CREATE TABLE LOGISTIC_REGRESSION_SUMMARY (
    analysis_id VARCHAR PRIMARY KEY,
    table_name VARCHAR,
    target_variable VARCHAR,
    model_type VARCHAR,
    problem_type VARCHAR,
    test_accuracy FLOAT,
    test_precision FLOAT,
    test_recall FLOAT,
    test_f1_score FLOAT,
    test_roc_auc FLOAT,
    train_accuracy FLOAT,
    total_samples INTEGER,
    total_features INTEGER,
    n_classes INTEGER,
    confusion_matrix ARRAY,
    top_features ARRAY,
    performance_summary VARCHAR,
    recommendations VARCHAR,
    created_at TIMESTAMP
);
```

---

#### **5. DECISION_TREE_SUMMARY**
Same as Logistic Regression + additional columns:
```sql
    tree_depth INTEGER,
    n_leaves INTEGER,
    max_depth INTEGER,
    min_samples_split INTEGER,
    min_samples_leaf INTEGER
```

---

#### **6. XGBOOST_SUMMARY**
Same as Logistic Regression + additional columns:
```sql
    n_estimators INTEGER,
    max_depth INTEGER,
    learning_rate FLOAT,
    subsample FLOAT,
    colsample_bytree FLOAT
```

---

## âš™ï¸ Configuration

### **Backend Configuration** (`backend/services/config.py`)

```python
from dotenv import load_dotenv
import os

load_dotenv()

class Config:
    SNOWFLAKE_ACCOUNT = os.getenv("SNOWFLAKE_ACCOUNT")
    SNOWFLAKE_USER = os.getenv("SNOWFLAKE_USER")
    SNOWFLAKE_PASSWORD = os.getenv("SNOWFLAKE_PASSWORD")
    SNOWFLAKE_DATABASE = os.getenv("SNOWFLAKE_DATABASE")
    SNOWFLAKE_SCHEMA = os.getenv("SNOWFLAKE_SCHEMA")
    INGESTION_WAREHOUSE = os.getenv("INGESTION_WAREHOUSE")
```

### **Frontend Configuration** (`frontend/src/pages/Foresee.jsx`)

```javascript
const API_BASE_URL = "http://localhost:5000/api";
```

Change this to your backend URL in production.

---

### **Flask Configuration** (`backend/app.py`)

```python
ALLOWED_EXTENSIONS = {'csv'}
app.config['MAX_CONTENT_LENGTH'] = 500 * 1024 * 1024  # 500MB max
```

---

## ğŸ¤– Google Gemini Integration

### **Models Used**

| Agent | Model | Purpose |
|-------|-------|---------|
| Target Variable Agent | `gemini-2.5-flash-preview-05-20` | Analyze data & rank targets |
| Natural Language Agent | `gemini-2.5-flash-preview-05-20` | Generate PDF insights |

### **API Configuration**

```python
import google.generativeai as genai

genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
model = genai.GenerativeModel('models/gemini-2.5-flash-preview-05-20')

# Generate content
response = model.generate_content(prompt)
```

### **Rate Limits & Pricing**

- **Free Tier:** 15 requests/minute, 1500 requests/day
- **Paid Tier:** Higher limits available
- Check current pricing: https://ai.google.dev/pricing

---

## ğŸ”’ Security & Privacy

### **Data Isolation**
- Each workflow creates an **isolated Snowflake schema** (`WORKFLOW_<UUID>`)
- No data mixing between workflows
- Automatic cleanup on workflow deletion

### **API Security**
- CORS enabled for frontend-backend communication
- File size limits (500MB max)
- File type validation (CSV only)
- Secure filename sanitization

### **Data Privacy**
- Data stored in **your** Snowflake account (not ours)
- AI models (Gemini) don't retain your data
- Stateless API calls
- No data sent to third parties

### **Temporary Files**
- Uploaded files stored in system temp directory
- Automatically deleted after Snowflake upload
- No persistent local storage

---

## ğŸ› Troubleshooting

### **Backend won't start**

```bash
# Check Python version
python --version  # Should be 3.11+

# Verify .env file exists
cat .env  # macOS/Linux
type .env  # Windows

# Test Snowflake connection
python -c "from services.config import Config; print(Config.SNOWFLAKE_ACCOUNT)"
```

---

### **Frontend can't connect to backend**

```bash
# Verify backend is running
curl http://localhost:5000/api/health

# Check CORS is enabled in backend/app.py
# CORS(app) should be present

# Verify API_BASE_URL in frontend matches backend port
```

---

### **Upload fails**

**Possible causes:**
1. **Invalid CSV format** - Verify file has headers and proper encoding
2. **Snowflake credentials** - Check `.env` variables
3. **Warehouse not running** - Start warehouse in Snowflake UI
4. **Insufficient credits** - Check Snowflake billing

---

### **Gemini API errors**

```bash
# Verify API key is set
echo $GEMINI_API_KEY  # macOS/Linux
echo %GEMINI_API_KEY%  # Windows

# Test API key manually
curl -H "Content-Type: application/json" \
     -d '{"contents":[{"parts":[{"text":"Hello"}]}]}' \
     "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key=YOUR_API_KEY"
```

**Common errors:**
- `INVALID_ARGUMENT`: Invalid API key
- `RESOURCE_EXHAUSTED`: Rate limit exceeded (wait 1 minute)
- `PERMISSION_DENIED`: API not enabled (enable in Google Cloud Console)

---

### **Model training fails**

**Possible causes:**
1. **Target has only 1 unique value** - Select different target
2. **Target has excessive nulls** (>50%) - Data quality issue
3. **Insufficient samples** (<50 rows) - Upload larger dataset
4. **All features are null** - Data quality issue

---

## ğŸ“ˆ Performance Optimizations

### **Parallel Execution**
- **EDA + Target Analysis** run in parallel using `ThreadPoolExecutor`
- Saves ~40% time compared to sequential execution
- Typical time saved: 20-30 seconds

### **Snowflake Optimizations**
- Uses `PUT` command for fast bulk loading
- Isolated schemas reduce query overhead
- Warehouse auto-suspend to reduce costs

### **Frontend Optimizations**
- Vite for fast builds and HMR (Hot Module Replacement)
- Code splitting with React Router
- Lazy loading of heavy components

---

## ğŸ“ Development Guidelines

### **Python Code Style**
- Follow **PEP 8** style guide
- Use type hints for function parameters
- Docstrings for all functions/classes
- Maximum line length: 100 characters

### **React Code Style**
- Use functional components with hooks
- ESLint for code linting
- Consistent file naming (PascalCase for components)
- PropTypes for type checking (optional)

### **Git Workflow**
```bash
# Create feature branch
git checkout -b feature/your-feature-name

# Make changes and commit
git add .
git commit -m "Add: your feature description"

# Push to remote
git push origin feature/your-feature-name

# Open Pull Request on GitHub
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. **Fork** the repository
2. Create a **feature branch** (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. Open a **Pull Request**

---

## ğŸ“ License

This project is licensed under the **MIT License**.

---

## ğŸ™ Acknowledgments

### **Technologies**
- **Snowflake** - Enterprise data platform
- **Google Gemini** - AI-powered insights (gemini-2.5-flash-preview-05-20)
- **React** - Modern web framework
- **Flask** - Lightweight Python API
- **scikit-learn** & **XGBoost** - ML frameworks
- **ReportLab** - Professional PDF generation

### **Team**
Built with â¤ï¸ by the **Foresee Team**

---

## ğŸ“ Support

For issues, questions, or suggestions:

- ğŸ› **Issues:** [GitHub Issues](https://github.com/yourusername/foresee-app/issues)
- ğŸ“§ **Email:** support@foresee-app.com
- ğŸ“š **Documentation:** [GitHub Wiki](https://github.com/yourusername/foresee-app/wiki)

---

## ğŸš€ Roadmap

### **Planned Features**
- [ ] Support for more ML models (Random Forest, Neural Networks)
- [ ] Advanced hyperparameter tuning (GridSearchCV)
- [ ] Time series forecasting support
- [ ] Interactive charts in PDF reports
- [ ] Model deployment API (FastAPI)
- [ ] Scheduled re-training
- [ ] User authentication (OAuth 2.0)
- [ ] Multi-user workspaces
- [ ] Excel file support (.xlsx)
- [ ] Real-time model monitoring dashboard
- [ ] SHAP value visualizations
- [ ] Model versioning & comparison

---

**Happy Analyzing! ğŸš€ğŸ“Š**

*Transform your data into insights with the power of AI.*